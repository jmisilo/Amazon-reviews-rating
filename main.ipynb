{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d52ecdb6",
   "metadata": {},
   "source": [
    "## 1. Import depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4cb07cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\workspace\\python\\amazon-rev-sent-analysis\\venv\\lib\\site-packages\\setuptools\\distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import functools\n",
    "import operator \n",
    "import json\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from dataclasses import dataclass\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner', 'parser'])\n",
    "stopwords = nlp.Defaults.stop_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a34114",
   "metadata": {},
   "source": [
    "## 2. Data works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07c85a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovs = pd.read_csv('data/preprocessed.csv')['overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0faccc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovs = ovs.value_counts().to_dict()\n",
    "k = ovs.keys()\n",
    "v = ovs.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a55829b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 5 artists>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f52ef080",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        \n",
    "        self.vocab = {\n",
    "            '<unk>': 0,\n",
    "            '<pad>': 1,\n",
    "            '<sos>': 2,\n",
    "            '<eos>': 3\n",
    "        }\n",
    "        \n",
    "        self.build_vocab()\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        assert type(index) in [str, int], 'Index type must be string or int'\n",
    "        \n",
    "        if isinstance(index, str):\n",
    "            try:\n",
    "                return self.vocab[index]\n",
    "            \n",
    "            except KeyError:\n",
    "                return self.vocab['<unk>']\n",
    "        \n",
    "        elif isinstance(index, int):\n",
    "            try:\n",
    "                return list(self.vocab.keys())[list(self.vocab.values()).index(index)]\n",
    "            except (KeyError,ValueError):\n",
    "                return self[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.vocab)\n",
    "    \n",
    "    def append_word(self, word):\n",
    "        if not word in self.vocab:\n",
    "            self.vocab[word] = len(self)\n",
    "    \n",
    "    def build_vocab(self):\n",
    "        bag_of_words = sorted(list(set(self.data)))\n",
    "        \n",
    "        for word in bag_of_words:\n",
    "            self.append_word(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b906f444",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RevDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.path = 'data/Video_Games_5.json'\n",
    "        self.prep_path = 'data/preprocessed.csv'\n",
    "        \n",
    "        # if preprocessed data already exists - load it\n",
    "        if os.path.isfile(self.prep_path):\n",
    "            self.data = pd.read_csv(self.prep_path)[['reviewText', 'overall']]\n",
    "        \n",
    "        # else preprocess and save\n",
    "        else:\n",
    "            with open(self.path, 'r') as f:\n",
    "                lines = [json.loads(line.rstrip()) for line in f]\n",
    "                self.data = pd.DataFrame(lines)[['verified', 'reviewText', 'overall']]\n",
    "                self.data = self.data[self.data['verified']]\n",
    "\n",
    "            self.data = self.data.dropna()\n",
    "            self.data = self.data.reset_index(drop=True)\n",
    "            self.data = self.data.drop('verified', axis=1)\n",
    "\n",
    "            self.data['reviewText'] = self.data['reviewText'].apply(self.clean_data)\n",
    "            self.tok_lemma()\n",
    "\n",
    "            self.data.to_csv(self.prep_path)\n",
    "            \n",
    "        self.build_vocab()\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        assert type(index) == int, 'Index must be int'\n",
    "        \n",
    "        item = self.data.iloc[index]\n",
    "        text = str(item['reviewText']).split()\n",
    "        \n",
    "        for i, word in enumerate(text):\n",
    "            text[i] = self.Voc[word]\n",
    "            \n",
    "        return text, item['overall']\n",
    "    \n",
    "    @staticmethod\n",
    "    def clean_data(text):\n",
    "        if type(text) != str:\n",
    "            return '   '\n",
    "        \n",
    "        # lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # remove \\n signs\n",
    "        text = text.replace('\\n\\n\\n\\n', ' ').replace('\\n\\n\\n', ' ').replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "        \n",
    "        # remove url\n",
    "        text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "        \n",
    "        # remove punctuations\n",
    "        text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "        return text \n",
    "    \n",
    "    def tok_lemma(self):\n",
    "        reviews = self.data['reviewText'].values\n",
    "\n",
    "        reviews = nlp.pipe(reviews, batch_size=128, n_process=3)\n",
    "\n",
    "        reviews = [' '.join([word.lemma_ for word in text if not word in stopwords and word.lemma_ and word.text.isalpha()]) for text in reviews]\n",
    "\n",
    "        self.data['reviewText'] = pd.Series(reviews) \n",
    "        \n",
    "    def build_vocab(self):\n",
    "        bag_of_words = self.data['reviewText'].apply(lambda x: str(x).split()).tolist()\n",
    "\n",
    "        bag_of_words = functools.reduce(operator.iconcat, bag_of_words, [])\n",
    "        \n",
    "        self.Voc = Vocabulary(bag_of_words)\n",
    "\n",
    "        self.Voc.build_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b91f07a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = RevDataset()\n",
    "vocab = data.Voc\n",
    "\n",
    "full_len = len(data)\n",
    "train_len = int(0.8 * full_len)\n",
    "test_len = int(0.1 * full_len)\n",
    "valid_len = full_len - (train_len + test_len)\n",
    "\n",
    "train_set, test_set, valid_set = random_split(data, [train_len, test_len, valid_len])\n",
    "\n",
    "del full_len, train_len, test_len, valid_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e734e81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class cfg:\n",
    "    epochs = 20\n",
    "    max_length = 310\n",
    "    embed_size = 120\n",
    "    hidden_size = 512\n",
    "    num_layers = 3\n",
    "    heads = 8\n",
    "    batch_size = 32\n",
    "    lr = 1.5e-6\n",
    "    vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d381485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lens = [len(data[i][0]) for i in range(len(data)) if len(data[i][0]) < 500]\n",
    "# plt.figure(figsize=(11, 8))\n",
    "# sns.histplot(data=lens, bins=15, kde=True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "958c6e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(batch):\n",
    "    reviews = []\n",
    "    overalls = []\n",
    "    for i, (text, overall) in enumerate(batch):\n",
    "        \n",
    "        text_len = len(text)\n",
    "        \n",
    "        if text_len == cfg.max_length:\n",
    "            pass\n",
    "        elif text_len > cfg.max_length:\n",
    "            text = text[:cfg.max_length]\n",
    "        else:\n",
    "            pad_len = cfg.max_length - text_len\n",
    "            for j in range(pad_len):\n",
    "                # 1 - index of <pad> token in Vocabulary\n",
    "                text.append(1)\n",
    "        reviews.append(torch.Tensor(text).type(torch.int64))\n",
    "        overalls.append(int(overall) - 1)\n",
    "    \n",
    "    overalls = torch.LongTensor(overalls)\n",
    "\n",
    "    return torch.stack(reviews), overalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d090f8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=32, collate_fn=pad_seq, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=32, collate_fn=pad_seq)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32, collate_fn=pad_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07db45b",
   "metadata": {},
   "source": [
    "## 3. Model\n",
    "\n",
    "Model implementation inspired by Alladin Persson's [movie](https://www.youtube.com/watch?v=U0s0f995w14). [GitHub repo](https://github.com/aladdinpersson/Machine-Learning-Collection/blob/master/ML/Pytorch/more_advanced/transformer_from_scratch/transformer_from_scratch.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0ce34fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self, embed_size, heads):\n",
    "        super(SelfAttention, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = embed_size // heads\n",
    "        \n",
    "        assert self.head_dim * heads == embed_size, 'Embed size needs to be divisible by heads'\n",
    "        \n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        \n",
    "        self.fc_out = nn.Linear(heads*self.head_dim, embed_size)\n",
    "        \n",
    "    def forward(self, values, keys, queries, mask):\n",
    "        N = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "        \n",
    "        values = values.reshape(N, value_len, self.heads, self.head_dim)\n",
    "        keys = keys.reshape(N, key_len, self.heads, self.head_dim)\n",
    "        queries = queries.reshape(N, query_len, self.heads, self.head_dim)\n",
    "        \n",
    "        values = self.values(values) \n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "        \n",
    "        energy = torch.einsum('nqhd, nkhd->nhqk', [queries, keys])\n",
    "        \n",
    "        if mask is not None:\n",
    "            # if mask at same point is 0 - shitdown this point - set to -inf, in softmax it will be 0\n",
    "            energy = energy.masked_fill(mask == 0, -1e20)\n",
    "            \n",
    "        attention = torch.softmax(energy / (self.embed_size**(1/2)), dim=3)\n",
    "        \n",
    "        # attention shape: N, heads, query_len, key_len\n",
    "        # values shape: N, value_len, heads, head_dim\n",
    "        # out shape: N, query_len, heads, head_dim\n",
    "        out = torch.einsum('nhql, nlhd->nqhd', [attention, values])\n",
    "        \n",
    "        out = out.reshape(N, query_len, self.heads*self.head_dim)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2411bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embed_size, heads, dropout, forward_expansion):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = SelfAttention(embed_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(embed_size)\n",
    "        self.norm2 = nn.LayerNorm(embed_size)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(embed_size, forward_expansion*embed_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion*embed_size, embed_size)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, value, key, queries, mask):\n",
    "        attention = self.attention(value, key, queries, mask)\n",
    "        \n",
    "        x = self.dropout(self.norm1(attention + queries))\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.dropout(self.norm2(forward + x))\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd1e6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, num_layers, max_length, heads, device, forward_expansion, dropout):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "        self.embed_size = embed_size\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        self.position_embedding = nn.Embedding(max_length, embed_size)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                TransformerBlock(\n",
    "                    embed_size,\n",
    "                    heads,\n",
    "                    dropout=dropout,\n",
    "                    forward_expansion=forward_expansion,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.fc1 = nn.Linear(max_length*embed_size, max_length*forward_expansion)\n",
    "        self.fc2 = nn.Linear(max_length*forward_expansion, max_length)\n",
    "        \n",
    "        self.fc_out = nn.Linear(max_length, 5)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        N, seq_len = x.shape\n",
    "\n",
    "        positions = torch.arange(0, seq_len).expand(N, seq_len).to(self.device)\n",
    "\n",
    "        x = self.dropout(self.word_embedding(x) + self.position_embedding(positions))\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, x, x, mask)\n",
    "\n",
    "        # x shape: N, max_length, embed_size\n",
    "        # flat x\n",
    "        x = x.reshape(N, -1)\n",
    "        \n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        \n",
    "        # out shape: N, 5\n",
    "        out = torch.softmax(self.fc_out(x), dim=1)\n",
    "        \n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dae5499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23d9fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    vocab_size=cfg.vocab_size, \n",
    "    embed_size=cfg.embed_size, \n",
    "    num_layers=cfg.num_layers, \n",
    "    max_length=cfg.max_length,\n",
    "    heads=cfg.heads, \n",
    "    device=device, \n",
    "    forward_expansion=4, \n",
    "    dropout=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f0129d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=cfg.lr)\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105c82b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(epoch, loader, model, optimizer, criterion, n_iter):\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    tot_samples = 0 \n",
    "    \n",
    "    no_batches = len(loader)\n",
    "    \n",
    "    print(f'EPOCH {epoch+1}')\n",
    "    \n",
    "    for batch_idx, (source, target) in enumerate(loader):\n",
    "        source = source.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        # backward propagation\n",
    "        scores = model(source)\n",
    "        loss = criterion(scores, target)\n",
    "\n",
    "        # forward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        _, pred = scores.max(1)\n",
    "\n",
    "        corr += (pred == target).sum()\n",
    "        tot_samples += pred.size(0)\n",
    "        \n",
    "        if (batch_idx + 1) % int(no_batches * .3) == 0: # .3 - beacouse it should print log ~3 times per epoch\n",
    "            n_iter += 1\n",
    "            \n",
    "            lss = running_loss / tot_samples\n",
    "            acc = corr / tot_samples\n",
    "            \n",
    "            print(f'Epoch: {epoch + 1} Batch: {batch_idx}/{no_batches} Loss: {lss}, Accuracy: {acc}')\n",
    "            writer.add_scalar('Loss/train', lss, n_iter)\n",
    "            writer.add_scalar('Accuracy/train', acc, n_iter)\n",
    "\n",
    "            running_loss = 0\n",
    "            corr = 0\n",
    "            tot_samples = 0 \n",
    "            \n",
    "    return running_loss, corr, tot_samples, n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba6c5855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch(epoch, loader, model):\n",
    "    running_loss = 0\n",
    "    corr = 0\n",
    "    tot_samples = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_idx, (source, target) in enumerate(loader):\n",
    "            source = source.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            scores = model(source)\n",
    "            loss = criterion(scores, target)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "            _, pred = scores.max(1)\n",
    "\n",
    "            corr += (pred == target).sum()\n",
    "            tot_samples += pred.size(0)\n",
    "            \n",
    "        model.train()\n",
    "        \n",
    "    lss = running_loss / tot_samples\n",
    "    acc = corr / tot_samples\n",
    "    \n",
    "    print(f'Epoch: {epoch + 1} VLoss: {lss}, VAccuracy: {acc}')\n",
    "    \n",
    "    writer.add_scalar('Loss/valid', lss, epoch)\n",
    "    writer.add_scalar('Accuracy/valid', acc, epoch)\n",
    "    \n",
    "    return running_loss, corr, tot_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c68e5231",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "SD_PATH = 'models/model-1644595693.1664352.pt'\n",
    "\n",
    "if os.path.exists(SD_PATH):\n",
    "    model.load_state_dict(torch.load(SD_PATH, map_location=device))\n",
    "else:\n",
    "    n_iter = 0\n",
    "    vn_iter = 0\n",
    "\n",
    "    for epoch in range(cfg.epochs):       \n",
    "        loss, corr, samples, n_iter = train_epoch(epoch, train_loader, model, optimizer, criterion, n_iter)\n",
    "        val_loss, val_corr, val_samples = valid_epoch(epoch, valid_loader, model)\n",
    "\n",
    "    torch.save(model.state_dict(), f'models/model-{time.time()}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78d03f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "true_values = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for batch_idx, (source, target) in enumerate(test_loader):\n",
    "        source = source.to(device)\n",
    "        target = target.to(device)\n",
    "        \n",
    "        scores = model(source)\n",
    "        \n",
    "        _, pred = scores.max(1)\n",
    "        \n",
    "        predictions.extend(pred.tolist())\n",
    "        true_values.extend(target.tolist())\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0183dfeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8169624060150376"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(true_values, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ff5f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazon-rev",
   "language": "python",
   "name": "amazon-rev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
